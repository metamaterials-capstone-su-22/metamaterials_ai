{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/spencersong/metamaterials_ai/src\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if is_init:\n",
    "        pass\n",
    "except:\n",
    "    %pwd\n",
    "    %cd ..\n",
    "    %pwd\n",
    "    is_init = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from src.utils import FileUtils\n",
    "from config import Config\n",
    "import torch\n",
    "import numpy as np\n",
    "work_folder = '../local_work'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Model Only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import InverseModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../local_work/saved_best/best_I-cnn-inconel-2022-07-05_04-49.ckpt\n"
     ]
    }
   ],
   "source": [
    "filepath = Path(\n",
    "    f\"{work_folder}/saved_best/best_I-cnn-inconel-2022-07-05_04-49.ckpt\")\n",
    "print(filepath)\n",
    "if not Path.is_file(filepath):\n",
    "    raise Exception(f'Model file does not exist at {filepath}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parhammotameni/anaconda3/envs/meta/lib/python3.10/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/home/parhammotameni/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:217: UserWarning: Found keys that are not in the model state dict but in the checkpoint: ['direct_model.model.0.weight', 'direct_model.model.0.bias', 'direct_model.model.2.layers.0.block.0.weight', 'direct_model.model.2.layers.0.block.0.bias', 'direct_model.model.2.layers.1.block.0.weight', 'direct_model.model.2.layers.1.block.0.bias', 'direct_model.model.2.layers.2.block.0.weight', 'direct_model.model.2.layers.2.block.0.bias', 'direct_model.model.2.layers.3.block.0.weight', 'direct_model.model.2.layers.3.block.0.bias', 'direct_model.model.2.layers.4.block.0.weight', 'direct_model.model.2.layers.4.block.0.bias', 'direct_model.model.2.layers.5.block.0.weight', 'direct_model.model.2.layers.5.block.0.bias', 'direct_model.model.2.layers.6.block.0.weight', 'direct_model.model.2.layers.6.block.0.bias', 'direct_model.model.2.layers.7.block.0.weight', 'direct_model.model.2.layers.7.block.0.bias', 'direct_model.model.2.layers.8.block.0.weight', 'direct_model.model.2.layers.8.block.0.bias', 'direct_model.model.2.layers.9.block.0.weight', 'direct_model.model.2.layers.9.block.0.bias', 'direct_model.model.2.layers.10.block.0.weight', 'direct_model.model.2.layers.10.block.0.bias', 'direct_model.model.2.layers.11.block.0.weight', 'direct_model.model.2.layers.11.block.0.bias', 'direct_model.model.2.layers.12.block.0.weight', 'direct_model.model.2.layers.12.block.0.bias', 'direct_model.model.2.layers.13.block.0.weight', 'direct_model.model.2.layers.13.block.0.bias', 'direct_model.model.2.layers.14.block.0.weight', 'direct_model.model.2.layers.14.block.0.bias', 'direct_model.model.2.layers.15.block.0.weight', 'direct_model.model.2.layers.15.block.0.bias', 'direct_model.model.3.weight', 'direct_model.model.3.bias']\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = InverseModel.load_from_checkpoint(filepath, strict=False)\n",
    "model.eval()\n",
    "x = torch.randn(1, 800)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_hat = model(x)\n",
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700.0 42.0\n",
      "10.0 1.0\n"
     ]
    }
   ],
   "source": [
    "data_folder = '../local_data'\n",
    "params = torch.load(\n",
    "        Path(f\"{data_folder}/stainless_steel.pt\"))[\"laser_params\"]\n",
    "max_speed, max_spacing = params.max(0)[0][0].item(), params.max(0)[0][1].item()\n",
    "min_speed, min_spacing = params.min(0)[0][0].item(), params.min(0)[0][1].item()\n",
    "print(max_speed, max_spacing)\n",
    "print(min_speed, min_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_decode_result(y_hat, max_speed, max_spacing, min_speed, min_spacing):\n",
    "    \"\"\"input: 1,14 tensor\n",
    "        output: 1,3 tensor with wattage no longer one hot encoded\"\"\"\n",
    "    watts = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3]\n",
    "\n",
    "    watt_arg = torch.argmax(y_hat[0][2:]) \n",
    "    y_final = torch.empty(3, dtype=torch.float32)\n",
    "    y_final[0] = min_speed + (max_speed - min_speed)* y_hat[0][0] # TODO call the scale\n",
    "    y_final[1] = min_spacing + (max_spacing - min_spacing) * y_hat[0][1] # TODO call the scale\n",
    "    y_final[2]= watts[watt_arg]\n",
    "    return y_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_hat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/spencersong/metamaterials_ai/src/notebooks/predictor.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B128.3.29.45/home/spencersong/metamaterials_ai/src/notebooks/predictor.ipynb#ch0000010vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# y_final2 = onehot_to_continuous2(y_hat)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B128.3.29.45/home/spencersong/metamaterials_ai/src/notebooks/predictor.ipynb#ch0000010vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(denormalize_decode_result(y_hat,max_speed, max_spacing, min_speed, min_spacing))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_hat' is not defined"
     ]
    }
   ],
   "source": [
    "# y_final2 = onehot_to_continuous2(y_hat)\n",
    "print(denormalize_decode_result(y_hat,max_speed, max_spacing, min_speed, min_spacing))\n",
    "\n",
    "#if you want hardcoded max, min values instead\n",
    "#print(denormalize_decode_result(y_hat,700.0, 42.0, 10.0, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct Model Only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import DirectModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filepath = Path(\n",
    "    f\"{work_folder}/saved_best/best_D-ann-inconel-2022-07-05_03-18.ckpt\")\n",
    "print(filepath)\n",
    "if not Path.is_file(filepath):\n",
    "    raise Exception(f'Model file does not exist at {filepath}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DirectModel.load_from_checkpoint(filepath)\n",
    "model.eval()\n",
    "x = torch.randn(1, 14)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_hat = model(x)\n",
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnxruntime \n",
    "# from pathlib import Path\n",
    "# import numpy as np\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session = onnxruntime.InferenceSession(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = Path(f\"{work_folder}/saved_best/best_inference_direct.onnx\")\n",
    "\n",
    "# ort_session = onnxruntime.InferenceSession(filepath)\n",
    "# input_name = ort_session.get_inputs()[0].name\n",
    "# ort_inputs = {input_name: np.random.randn(2, 14)}\n",
    "# ort_outs = ort_session.run(None, ort_inputs)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "67e7f89d5252d36c0a7a22a0bddaf9ce6b4bb105a5aa258c373ad72ae6e9c8c8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('meta')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8002f67306fdf03846a85192394013d7a0803f94603193c08381e3348b7b52be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
