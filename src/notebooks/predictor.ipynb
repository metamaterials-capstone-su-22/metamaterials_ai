{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if is_init:\n",
    "        pass\n",
    "except:\n",
    "    %pwd\n",
    "    %cd ..\n",
    "    %pwd\n",
    "    is_init = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from src.utils import FileUtils\n",
    "from config import Config\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "data_folder = '../local_data'\n",
    "work_folder = '../local_work'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unexplored Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.load(\n",
    "                Path(f\"{data_folder}/inconel-revised-raw-shuffled.pt\"))[\"laser_params\"] #stainless-steel-revised-shuffled inconel-revised-raw-shuffled\n",
    "max_speed, max_spacing = params.max(0)[0][0].item(), params.max(0)[0][1].item()\n",
    "min_speed, min_spacing = params.min(0)[0][0].item(), params.min(0)[0][1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_decode_result(y_hat, max_speed, max_spacing, min_speed, min_spacing):\n",
    "    \"\"\"input: 1,14 tensor\n",
    "        output: 1,3 tensor with wattage no longer one hot encoded\"\"\"\n",
    "    watts = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3]\n",
    "\n",
    "    watt_arg = torch.argmax(y_hat[0][2:])\n",
    "    y_final = torch.empty(3, dtype=torch.float32)\n",
    "    y_final[0] = max_speed * y_hat[0][0] # TODO call the scale\n",
    "    y_final[1] = max_spacing * y_hat[0][1] # TODO call the scale\n",
    "    y_final[2]= watts[watt_arg]\n",
    "    return y_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify explored param space\n",
    "\n",
    "def get_unexplored_params(params, max_speed, max_spacing, min_speed, min_spacing, n = 196, seed = 1):\n",
    "        \"\"\"\n",
    "        finds unexplored parameters\n",
    "        inputs: tensor of [[], [], []], each size (1,14)\n",
    "        outputs: list of n unnormalized tuples each of size (1,3)\"\"\"\n",
    "        param_space = [np.arange(min_speed, max_speed + 10, 10).tolist(), np.arange(min_spacing, max_spacing + 1, 1).tolist(), np.around(np.arange(.2, 1.4, .1), decimals = 1).tolist()]\n",
    "        #get set of all possible parameter combinations\n",
    "        param_all_comb = set(list(itertools.product(*param_space)))#[list(tup) for tup in itertools.product(*param_space)]\n",
    "        wattages = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3]\n",
    "        #get set of all training parameter combinations\n",
    "        train_param_space = set([tuple(x[:2] + [wattages[np.argmax(x[2:])]]) for x in params.tolist()]) #29988\n",
    "        #find the combination parameters NOT in the training space\n",
    "        unused_params = list(param_all_comb.symmetric_difference(train_param_space)) #len() = 5292\n",
    "        random.seed = seed\n",
    "        indices = random.sample(range(len(unused_params)), n)\n",
    "        return [unused_params[i] for i in indices]\n",
    "\n",
    "def unexplored_params_to_tensors(x):\n",
    "        new_x = []\n",
    "        wattage_idxs = {\n",
    "                0.2: 0,\n",
    "                0.3: 1,\n",
    "                0.4: 2,\n",
    "                0.5: 3,\n",
    "                0.6: 4,\n",
    "                0.7: 5,\n",
    "                0.8: 6,\n",
    "                0.9: 7,\n",
    "                1.0: 8,\n",
    "                1.1: 9,\n",
    "                1.2: 10,\n",
    "                1.3: 11,\n",
    "        }      \n",
    "        for i in x:\n",
    "                i = list(i)\n",
    "                holder = i[:2] + np.zeros(12).tolist()\n",
    "                holder[wattage_idxs[i[2]] + 2] = 1.0\n",
    "                new_x.append(holder)\n",
    "\n",
    "        laser_params = torch.FloatTensor(new_x)\n",
    "        return laser_params / laser_params.max(0).values\n",
    "\n",
    "#[torch.cat((x[:2], torch.tensor(np.array([wattages[np.argmax(x[2:])]])))) for x in params]#[:5]\n",
    "#[x[:2] for x in params]#[:5]\n",
    "\n",
    "# train_param_space = denormalize_decode_result(params, max_speed, max_spacing, min_speed, min_spacing)\n",
    "# train_param_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouput_unexplored = get_unexplored_params(params, max_speed, max_spacing, min_speed, min_spacing, n = 196, seed = 1)\n",
    "norm_unexplored_laser_params = unexplored_params_to_tensors(ouput_unexplored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Model Only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import InverseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../local_work/saved_best/best_B-ann-stainless-2022-07-02_01-25.ckpt\n"
     ]
    }
   ],
   "source": [
    "filepath = Path(\n",
    "    f\"{work_folder}/saved_best/best_B-ann-stainless-2022-07-02_01-25.ckpt\") #CHANGEME inconel vs stainless best model\n",
    "print(filepath)\n",
    "if not Path.is_file(filepath):\n",
    "    raise Exception(f'Model file does not exist at {filepath}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for InverseModel:\n\tsize mismatch for model.0.weight: copying a param with shape torch.Size([1000, 800]) from checkpoint, the shape in current model is torch.Size([1200, 800]).\n\tsize mismatch for model.0.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([1200]).\n\tsize mismatch for model.2.layers.0.block.0.weight: copying a param with shape torch.Size([1000, 1000]) from checkpoint, the shape in current model is torch.Size([1200, 1200]).\n\tsize mismatch for model.2.layers.0.block.0.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([1200]).\n\tsize mismatch for model.2.layers.1.block.0.weight: copying a param with shape torch.Size([1000, 1000]) from checkpoint, the shape in current model is torch.Size([1200, 1200]).\n\tsize mismatch for model.2.layers.1.block.0.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([1200]).\n\tsize mismatch for model.2.layers.2.block.0.weight: copying a param with shape torch.Size([1000, 1000]) from checkpoint, the shape in current model is torch.Size([1200, 1200]).\n\tsize mismatch for model.2.layers.2.block.0.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([1200]).\n\tsize mismatch for model.2.layers.3.block.0.weight: copying a param with shape torch.Size([1000, 1000]) from checkpoint, the shape in current model is torch.Size([1200, 1200]).\n\tsize mismatch for model.2.layers.3.block.0.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([1200]).\n\tsize mismatch for model.2.layers.4.block.0.weight: copying a param with shape torch.Size([1000, 1000]) from checkpoint, the shape in current model is torch.Size([1200, 1200]).\n\tsize mismatch for model.2.layers.4.block.0.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([1200]).\n\tsize mismatch for model.2.layers.5.block.0.weight: copying a param with shape torch.Size([1000, 1000]) from checkpoint, the shape in current model is torch.Size([1200, 1200]).\n\tsize mismatch for model.2.layers.5.block.0.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([1200]).\n\tsize mismatch for model.3.weight: copying a param with shape torch.Size([14, 1000]) from checkpoint, the shape in current model is torch.Size([14, 1200]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/spencersong/metamaterials_ai/src/notebooks/predictor.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B128.3.29.45/home/spencersong/metamaterials_ai/src/notebooks/predictor.ipynb#ch0000012vscode-remote?line=0'>1</a>\u001b[0m i_model \u001b[39m=\u001b[39m InverseModel\u001b[39m.\u001b[39;49mload_from_checkpoint(filepath, strict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B128.3.29.45/home/spencersong/metamaterials_ai/src/notebooks/predictor.ipynb#ch0000012vscode-remote?line=1'>2</a>\u001b[0m i_model\u001b[39m.\u001b[39meval()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B128.3.29.45/home/spencersong/metamaterials_ai/src/notebooks/predictor.ipynb#ch0000012vscode-remote?line=3'>4</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(np\u001b[39m.\u001b[39marray(torch\u001b[39m.\u001b[39mrandn(\u001b[39m1\u001b[39m, \u001b[39m800\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m3\u001b[39m)) \u001b[39m#\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:161\u001b[0m, in \u001b[0;36mModelIO.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py?line=157'>158</a>\u001b[0m \u001b[39m# override the hparams with values that were passed in\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py?line=158'>159</a>\u001b[0m checkpoint[\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mCHECKPOINT_HYPER_PARAMS_KEY]\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py?line=160'>161</a>\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_load_model_state(checkpoint, strict\u001b[39m=\u001b[39;49mstrict, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py?line=161'>162</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:209\u001b[0m, in \u001b[0;36mModelIO._load_model_state\u001b[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[1;32m    <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py?line=205'>206</a>\u001b[0m model\u001b[39m.\u001b[39mon_load_checkpoint(checkpoint)\n\u001b[1;32m    <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py?line=207'>208</a>\u001b[0m \u001b[39m# load the state_dict on the model automatically\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py?line=208'>209</a>\u001b[0m keys \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mload_state_dict(checkpoint[\u001b[39m\"\u001b[39;49m\u001b[39mstate_dict\u001b[39;49m\u001b[39m\"\u001b[39;49m], strict\u001b[39m=\u001b[39;49mstrict)\n\u001b[1;32m    <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py?line=210'>211</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m strict:\n\u001b[1;32m    <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py?line=211'>212</a>\u001b[0m     \u001b[39mif\u001b[39;00m keys\u001b[39m.\u001b[39mmissing_keys:\n",
      "File \u001b[0;32m~/anaconda3/envs/meta/lib/python3.10/site-packages/torch/nn/modules/module.py:1497\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1491'>1492</a>\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1492'>1493</a>\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1493'>1494</a>\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1495'>1496</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1496'>1497</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1497'>1498</a>\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1498'>1499</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for InverseModel:\n\tsize mismatch for model.0.weight: copying a param with shape torch.Size([1000, 800]) from checkpoint, the shape in current model is torch.Size([1200, 800]).\n\tsize mismatch for model.0.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([1200]).\n\tsize mismatch for model.2.layers.0.block.0.weight: copying a param with shape torch.Size([1000, 1000]) from checkpoint, the shape in current model is torch.Size([1200, 1200]).\n\tsize mismatch for model.2.layers.0.block.0.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([1200]).\n\tsize mismatch for model.2.layers.1.block.0.weight: copying a param with shape torch.Size([1000, 1000]) from checkpoint, the shape in current model is torch.Size([1200, 1200]).\n\tsize mismatch for model.2.layers.1.block.0.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([1200]).\n\tsize mismatch for model.2.layers.2.block.0.weight: copying a param with shape torch.Size([1000, 1000]) from checkpoint, the shape in current model is torch.Size([1200, 1200]).\n\tsize mismatch for model.2.layers.2.block.0.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([1200]).\n\tsize mismatch for model.2.layers.3.block.0.weight: copying a param with shape torch.Size([1000, 1000]) from checkpoint, the shape in current model is torch.Size([1200, 1200]).\n\tsize mismatch for model.2.layers.3.block.0.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([1200]).\n\tsize mismatch for model.2.layers.4.block.0.weight: copying a param with shape torch.Size([1000, 1000]) from checkpoint, the shape in current model is torch.Size([1200, 1200]).\n\tsize mismatch for model.2.layers.4.block.0.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([1200]).\n\tsize mismatch for model.2.layers.5.block.0.weight: copying a param with shape torch.Size([1000, 1000]) from checkpoint, the shape in current model is torch.Size([1200, 1200]).\n\tsize mismatch for model.2.layers.5.block.0.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([1200]).\n\tsize mismatch for model.3.weight: copying a param with shape torch.Size([14, 1000]) from checkpoint, the shape in current model is torch.Size([14, 1200])."
     ]
    }
   ],
   "source": [
    "i_model = InverseModel.load_from_checkpoint(filepath, strict=False)\n",
    "i_model.eval()\n",
    "\n",
    "x = torch.from_numpy(np.array(torch.randn(1, 800) * 3)) #\n",
    "with torch.no_grad():\n",
    "    y_hat = i_model(x)\n",
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([203.2477,  11.1895,   0.3000])\n"
     ]
    }
   ],
   "source": [
    "# y_final2 = onehot_to_continuous2(y_hat)\n",
    "print(denormalize_decode_result(y_hat,max_speed, max_spacing, min_speed, min_spacing))\n",
    "\n",
    "#if you want hardcoded max, min values instead\n",
    "#print(denormalize_decode_result(y_hat,700.0, 42.0, 10.0, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct Model Only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import DirectModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../local_work/saved_best/best_D-ann-stainless-2022-07-07_03-08.ckpt\n"
     ]
    }
   ],
   "source": [
    "filepath = Path(\n",
    "    f\"{work_folder}/saved_best/best_D-ann-stainless-2022-07-07_03-08.ckpt\")\n",
    "print(filepath)\n",
    "if not Path.is_file(filepath):\n",
    "    raise Exception(f'Model file does not exist at {filepath}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[40., 40.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [20., 20.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [40., 40.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DirectModel:\n\tUnexpected key(s) in state_dict: \"continuous_head.weight\", \"continuous_head.bias\", \"discrete_head.weight\", \"discrete_head.bias\", \"direct_model.model.0.weight\", \"direct_model.model.0.bias\", \"direct_model.model.2.layers.0.block.0.weight\", \"direct_model.model.2.layers.0.block.0.bias\", \"direct_model.model.2.layers.1.block.0.weight\", \"direct_model.model.2.layers.1.block.0.bias\", \"direct_model.model.2.layers.2.block.0.weight\", \"direct_model.model.2.layers.2.block.0.bias\", \"direct_model.model.2.layers.3.block.0.weight\", \"direct_model.model.2.layers.3.block.0.bias\", \"direct_model.model.2.layers.4.block.0.weight\", \"direct_model.model.2.layers.4.block.0.bias\", \"direct_model.model.2.layers.5.block.0.weight\", \"direct_model.model.2.layers.5.block.0.bias\", \"direct_model.model.2.layers.6.block.0.weight\", \"direct_model.model.2.layers.6.block.0.bias\", \"direct_model.model.2.layers.7.block.0.weight\", \"direct_model.model.2.layers.7.block.0.bias\", \"direct_model.model.2.layers.8.block.0.weight\", \"direct_model.model.2.layers.8.block.0.bias\", \"direct_model.model.2.layers.9.block.0.weight\", \"direct_model.model.2.layers.9.block.0.bias\", \"direct_model.model.2.layers.10.block.0.weight\", \"direct_model.model.2.layers.10.block.0.bias\", \"direct_model.model.2.layers.11.block.0.weight\", \"direct_model.model.2.layers.11.block.0.bias\", \"direct_model.model.2.layers.12.block.0.weight\", \"direct_model.model.2.layers.12.block.0.bias\", \"direct_model.model.2.layers.13.block.0.weight\", \"direct_model.model.2.layers.13.block.0.bias\", \"direct_model.model.2.layers.14.block.0.weight\", \"direct_model.model.2.layers.14.block.0.bias\", \"direct_model.model.2.layers.15.block.0.weight\", \"direct_model.model.2.layers.15.block.0.bias\", \"direct_model.model.3.weight\", \"direct_model.model.3.bias\". \n\tsize mismatch for model.0.weight: copying a param with shape torch.Size([1200, 800]) from checkpoint, the shape in current model is torch.Size([512, 14]).\n\tsize mismatch for model.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.0.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.0.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.1.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.1.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.2.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.2.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.3.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.3.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.4.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.4.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.5.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.5.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.6.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.6.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.7.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.7.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.8.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.8.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.9.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.9.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.10.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.10.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.11.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.11.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.12.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.12.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.13.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.13.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.14.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.14.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.15.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.15.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.3.weight: copying a param with shape torch.Size([14, 1200]) from checkpoint, the shape in current model is torch.Size([800, 512]).\n\tsize mismatch for model.3.bias: copying a param with shape torch.Size([14]) from checkpoint, the shape in current model is torch.Size([800]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/spencersong/metamaterials_ai/src/notebooks/predictor.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B128.3.29.45/home/spencersong/metamaterials_ai/src/notebooks/predictor.ipynb#ch0000020vscode-remote?line=0'>1</a>\u001b[0m d_model \u001b[39m=\u001b[39m DirectModel\u001b[39m.\u001b[39;49mload_from_checkpoint(filepath)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B128.3.29.45/home/spencersong/metamaterials_ai/src/notebooks/predictor.ipynb#ch0000020vscode-remote?line=1'>2</a>\u001b[0m d_model\u001b[39m.\u001b[39meval()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B128.3.29.45/home/spencersong/metamaterials_ai/src/notebooks/predictor.ipynb#ch0000020vscode-remote?line=2'>3</a>\u001b[0m \u001b[39m# x = torch.randn(1, 14)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B128.3.29.45/home/spencersong/metamaterials_ai/src/notebooks/predictor.ipynb#ch0000020vscode-remote?line=3'>4</a>\u001b[0m \u001b[39m#direct_y_hats = []\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:161\u001b[0m, in \u001b[0;36mModelIO.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py?line=157'>158</a>\u001b[0m \u001b[39m# override the hparams with values that were passed in\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py?line=158'>159</a>\u001b[0m checkpoint[\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mCHECKPOINT_HYPER_PARAMS_KEY]\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py?line=160'>161</a>\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_load_model_state(checkpoint, strict\u001b[39m=\u001b[39;49mstrict, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py?line=161'>162</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:209\u001b[0m, in \u001b[0;36mModelIO._load_model_state\u001b[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[1;32m    <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py?line=205'>206</a>\u001b[0m model\u001b[39m.\u001b[39mon_load_checkpoint(checkpoint)\n\u001b[1;32m    <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py?line=207'>208</a>\u001b[0m \u001b[39m# load the state_dict on the model automatically\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py?line=208'>209</a>\u001b[0m keys \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mload_state_dict(checkpoint[\u001b[39m\"\u001b[39;49m\u001b[39mstate_dict\u001b[39;49m\u001b[39m\"\u001b[39;49m], strict\u001b[39m=\u001b[39;49mstrict)\n\u001b[1;32m    <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py?line=210'>211</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m strict:\n\u001b[1;32m    <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py?line=211'>212</a>\u001b[0m     \u001b[39mif\u001b[39;00m keys\u001b[39m.\u001b[39mmissing_keys:\n",
      "File \u001b[0;32m~/anaconda3/envs/meta/lib/python3.10/site-packages/torch/nn/modules/module.py:1497\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1491'>1492</a>\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1492'>1493</a>\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1493'>1494</a>\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1495'>1496</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1496'>1497</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1497'>1498</a>\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   <a href='file:///home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1498'>1499</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DirectModel:\n\tUnexpected key(s) in state_dict: \"continuous_head.weight\", \"continuous_head.bias\", \"discrete_head.weight\", \"discrete_head.bias\", \"direct_model.model.0.weight\", \"direct_model.model.0.bias\", \"direct_model.model.2.layers.0.block.0.weight\", \"direct_model.model.2.layers.0.block.0.bias\", \"direct_model.model.2.layers.1.block.0.weight\", \"direct_model.model.2.layers.1.block.0.bias\", \"direct_model.model.2.layers.2.block.0.weight\", \"direct_model.model.2.layers.2.block.0.bias\", \"direct_model.model.2.layers.3.block.0.weight\", \"direct_model.model.2.layers.3.block.0.bias\", \"direct_model.model.2.layers.4.block.0.weight\", \"direct_model.model.2.layers.4.block.0.bias\", \"direct_model.model.2.layers.5.block.0.weight\", \"direct_model.model.2.layers.5.block.0.bias\", \"direct_model.model.2.layers.6.block.0.weight\", \"direct_model.model.2.layers.6.block.0.bias\", \"direct_model.model.2.layers.7.block.0.weight\", \"direct_model.model.2.layers.7.block.0.bias\", \"direct_model.model.2.layers.8.block.0.weight\", \"direct_model.model.2.layers.8.block.0.bias\", \"direct_model.model.2.layers.9.block.0.weight\", \"direct_model.model.2.layers.9.block.0.bias\", \"direct_model.model.2.layers.10.block.0.weight\", \"direct_model.model.2.layers.10.block.0.bias\", \"direct_model.model.2.layers.11.block.0.weight\", \"direct_model.model.2.layers.11.block.0.bias\", \"direct_model.model.2.layers.12.block.0.weight\", \"direct_model.model.2.layers.12.block.0.bias\", \"direct_model.model.2.layers.13.block.0.weight\", \"direct_model.model.2.layers.13.block.0.bias\", \"direct_model.model.2.layers.14.block.0.weight\", \"direct_model.model.2.layers.14.block.0.bias\", \"direct_model.model.2.layers.15.block.0.weight\", \"direct_model.model.2.layers.15.block.0.bias\", \"direct_model.model.3.weight\", \"direct_model.model.3.bias\". \n\tsize mismatch for model.0.weight: copying a param with shape torch.Size([1200, 800]) from checkpoint, the shape in current model is torch.Size([512, 14]).\n\tsize mismatch for model.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.0.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.0.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.1.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.1.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.2.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.2.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.3.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.3.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.4.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.4.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.5.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.5.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.6.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.6.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.7.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.7.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.8.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.8.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.9.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.9.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.10.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.10.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.11.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.11.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.12.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.12.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.13.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.13.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.14.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.14.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.2.layers.15.block.0.weight: copying a param with shape torch.Size([1200, 1200]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for model.2.layers.15.block.0.bias: copying a param with shape torch.Size([1200]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for model.3.weight: copying a param with shape torch.Size([14, 1200]) from checkpoint, the shape in current model is torch.Size([800, 512]).\n\tsize mismatch for model.3.bias: copying a param with shape torch.Size([14]) from checkpoint, the shape in current model is torch.Size([800])."
     ]
    }
   ],
   "source": [
    "d_model = DirectModel.load_from_checkpoint(filepath)\n",
    "d_model.eval()\n",
    "# x = torch.randn(1, 14)\n",
    "#direct_y_hats = []\n",
    "intersect_preds = []\n",
    "for i in output:#norm_unexplored_laser_params:\n",
    "    with torch.no_grad():\n",
    "        intersect_preds#direct_y_hats.append(d_model(i.reshape(1,14)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unexplored Direct --> Indirect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InverseModel.load_from_checkpoint(filepath, strict=False)\n",
    "model.eval()\n",
    "\n",
    "x = torch.from_numpy(np.array(torch.randn(1, 800) * 3)) #\n",
    "param_preds = []\n",
    "for i in direct_y_hats:\n",
    "    with torch.no_grad():\n",
    "        param_preds.append(model(i))#model(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([250.0000, 250.0000,   1.2000]),\n",
       " tensor([250., 250.,   1.]),\n",
       " tensor([40.0000, 40.0000,  0.7000]),\n",
       " tensor([420.0000, 420.0000,   0.9000]),\n",
       " tensor([230.0000, 230.0000,   1.2000]),\n",
       " tensor([300.0000, 300.0000,   1.2000]),\n",
       " tensor([130.0000, 130.0000,   1.1000]),\n",
       " tensor([140.0000, 140.0000,   1.1000]),\n",
       " tensor([110.0000, 110.0000,   1.1000]),\n",
       " tensor([170.0000, 170.0000,   1.1000]),\n",
       " tensor([260., 260.,   1.]),\n",
       " tensor([160.0000, 160.0000,   1.1000]),\n",
       " tensor([210.0000, 210.0000,   1.1000]),\n",
       " tensor([320., 320.,   1.]),\n",
       " tensor([110.0000, 110.0000,   1.1000]),\n",
       " tensor([160.0000, 160.0000,   1.1000]),\n",
       " tensor([170., 170.,   1.]),\n",
       " tensor([310.0000, 310.0000,   1.2000]),\n",
       " tensor([250.0000, 250.0000,   1.2000]),\n",
       " tensor([80.0000, 80.0000,  1.1000]),\n",
       " tensor([110.0000, 110.0000,   1.1000]),\n",
       " tensor([90.0000, 90.0000,  0.7000]),\n",
       " tensor([90.0000, 90.0000,  1.1000]),\n",
       " tensor([100.0000, 100.0000,   1.1000]),\n",
       " tensor([160., 160.,   1.]),\n",
       " tensor([130.0000, 130.0000,   1.1000]),\n",
       " tensor([100.0000, 100.0000,   1.1000]),\n",
       " tensor([200.0000, 200.0000,   1.1000]),\n",
       " tensor([80.0000, 80.0000,  0.7000]),\n",
       " tensor([120.0000, 120.0000,   1.1000]),\n",
       " tensor([240., 240.,   1.]),\n",
       " tensor([250., 250.,   1.]),\n",
       " tensor([120.0000, 120.0000,   1.1000]),\n",
       " tensor([270., 270.,   1.]),\n",
       " tensor([40.0000, 40.0000,  0.7000]),\n",
       " tensor([90.0000, 90.0000,  1.1000]),\n",
       " tensor([150., 150.,   1.]),\n",
       " tensor([110.0000, 110.0000,   1.1000]),\n",
       " tensor([90.0000, 90.0000,  1.1000]),\n",
       " tensor([430.0000, 430.0000,   1.2000]),\n",
       " tensor([100.0000, 100.0000,   0.7000]),\n",
       " tensor([230., 230.,   1.]),\n",
       " tensor([210.0000, 210.0000,   1.2000]),\n",
       " tensor([660.0000, 660.0000,   1.2000]),\n",
       " tensor([150.0000, 150.0000,   1.1000]),\n",
       " tensor([540.0000, 540.0000,   1.2000]),\n",
       " tensor([370.0000, 370.0000,   1.2000]),\n",
       " tensor([80.0000, 80.0000,  1.1000]),\n",
       " tensor([100.0000, 100.0000,   1.1000]),\n",
       " tensor([340.0000, 340.0000,   1.2000]),\n",
       " tensor([90.0000, 90.0000,  1.1000]),\n",
       " tensor([130.0000, 130.0000,   1.1000]),\n",
       " tensor([150.0000, 150.0000,   1.1000]),\n",
       " tensor([210., 210.,   1.]),\n",
       " tensor([120.0000, 120.0000,   1.1000]),\n",
       " tensor([290.0000, 290.0000,   1.2000]),\n",
       " tensor([520.0000, 520.0000,   1.2000]),\n",
       " tensor([100.0000, 100.0000,   1.1000]),\n",
       " tensor([70.0000, 70.0000,  0.7000]),\n",
       " tensor([140., 140.,   1.]),\n",
       " tensor([100.0000, 100.0000,   1.1000]),\n",
       " tensor([80.0000, 80.0000,  1.1000]),\n",
       " tensor([280., 280.,   1.]),\n",
       " tensor([440.0000, 440.0000,   1.2000]),\n",
       " tensor([250.0000, 250.0000,   1.2000]),\n",
       " tensor([200.0000, 200.0000,   1.1000]),\n",
       " tensor([130.0000, 130.0000,   1.1000]),\n",
       " tensor([110.0000, 110.0000,   1.1000]),\n",
       " tensor([70.0000, 70.0000,  1.1000]),\n",
       " tensor([170.0000, 170.0000,   1.2000]),\n",
       " tensor([190.0000, 190.0000,   1.2000]),\n",
       " tensor([250.0000, 250.0000,   1.2000]),\n",
       " tensor([230.0000, 230.0000,   1.2000]),\n",
       " tensor([220.0000, 220.0000,   1.2000]),\n",
       " tensor([140.0000, 140.0000,   1.1000]),\n",
       " tensor([80.0000, 80.0000,  1.1000]),\n",
       " tensor([340.0000, 340.0000,   1.2000]),\n",
       " tensor([170., 170.,   1.]),\n",
       " tensor([50.0000, 50.0000,  0.7000]),\n",
       " tensor([140.0000, 140.0000,   1.1000]),\n",
       " tensor([90.0000, 90.0000,  1.1000]),\n",
       " tensor([90.0000, 90.0000,  1.1000]),\n",
       " tensor([130.0000, 130.0000,   1.1000]),\n",
       " tensor([80.0000, 80.0000,  1.1000]),\n",
       " tensor([90.0000, 90.0000,  1.1000]),\n",
       " tensor([350., 350.,   1.]),\n",
       " tensor([40.0000, 40.0000,  0.9000]),\n",
       " tensor([100.0000, 100.0000,   1.1000]),\n",
       " tensor([60.0000, 60.0000,  1.1000]),\n",
       " tensor([110.0000, 110.0000,   1.1000]),\n",
       " tensor([100.0000, 100.0000,   1.1000]),\n",
       " tensor([230., 230.,   1.]),\n",
       " tensor([370.0000, 370.0000,   1.2000]),\n",
       " tensor([420.0000, 420.0000,   1.2000]),\n",
       " tensor([490.0000, 490.0000,   1.2000]),\n",
       " tensor([130.0000, 130.0000,   1.1000]),\n",
       " tensor([110.0000, 110.0000,   0.7000]),\n",
       " tensor([320.0000, 320.0000,   1.2000]),\n",
       " tensor([510.0000, 510.0000,   1.2000]),\n",
       " tensor([110.0000, 110.0000,   1.1000]),\n",
       " tensor([270.0000, 270.0000,   1.2000]),\n",
       " tensor([70.0000, 70.0000,  1.1000]),\n",
       " tensor([120.0000, 120.0000,   1.1000]),\n",
       " tensor([130.0000, 130.0000,   1.1000]),\n",
       " tensor([90.0000, 90.0000,  1.1000]),\n",
       " tensor([80.0000, 80.0000,  1.1000]),\n",
       " tensor([160.0000, 160.0000,   1.1000]),\n",
       " tensor([60.0000, 60.0000,  1.1000]),\n",
       " tensor([310., 310.,   1.]),\n",
       " tensor([160.0000, 160.0000,   1.1000]),\n",
       " tensor([110.0000, 110.0000,   1.1000]),\n",
       " tensor([180., 180.,   1.]),\n",
       " tensor([270.0000, 270.0000,   1.2000]),\n",
       " tensor([140.0000, 140.0000,   1.1000]),\n",
       " tensor([220.0000, 220.0000,   1.1000]),\n",
       " tensor([250., 250.,   1.]),\n",
       " tensor([160.0000, 160.0000,   1.1000]),\n",
       " tensor([110.0000, 110.0000,   1.1000]),\n",
       " tensor([260.0000, 260.0000,   1.2000]),\n",
       " tensor([310.0000, 310.0000,   1.2000]),\n",
       " tensor([180.0000, 180.0000,   1.1000]),\n",
       " tensor([90.0000, 90.0000,  1.1000]),\n",
       " tensor([90.0000, 90.0000,  0.7000]),\n",
       " tensor([200.0000, 200.0000,   1.1000]),\n",
       " tensor([90.0000, 90.0000,  1.1000]),\n",
       " tensor([180.0000, 180.0000,   1.1000]),\n",
       " tensor([110.0000, 110.0000,   1.1000]),\n",
       " tensor([70.0000, 70.0000,  1.1000]),\n",
       " tensor([70.0000, 70.0000,  0.7000]),\n",
       " tensor([130.0000, 130.0000,   1.1000]),\n",
       " tensor([280.0000, 280.0000,   1.2000]),\n",
       " tensor([420.0000, 420.0000,   1.2000]),\n",
       " tensor([390.0000, 390.0000,   1.2000]),\n",
       " tensor([570.0000, 570.0000,   1.2000]),\n",
       " tensor([90.0000, 90.0000,  1.1000]),\n",
       " tensor([320.0000, 320.0000,   1.2000]),\n",
       " tensor([80.0000, 80.0000,  1.1000]),\n",
       " tensor([150.0000, 150.0000,   1.1000]),\n",
       " tensor([130.0000, 130.0000,   1.1000]),\n",
       " tensor([90.0000, 90.0000,  1.1000]),\n",
       " tensor([150., 150.,   1.]),\n",
       " tensor([580.0000, 580.0000,   1.2000]),\n",
       " tensor([220.0000, 220.0000,   1.1000]),\n",
       " tensor([90.0000, 90.0000,  1.1000]),\n",
       " tensor([200.0000, 200.0000,   1.2000]),\n",
       " tensor([210., 210.,   1.]),\n",
       " tensor([160.0000, 160.0000,   1.1000]),\n",
       " tensor([140.0000, 140.0000,   1.1000]),\n",
       " tensor([640.0000, 640.0000,   1.2000]),\n",
       " tensor([80.0000, 80.0000,  1.1000]),\n",
       " tensor([220.0000, 220.0000,   1.2000]),\n",
       " tensor([410.0000, 410.0000,   1.2000]),\n",
       " tensor([220.0000, 220.0000,   1.1000]),\n",
       " tensor([80.0000, 80.0000,  0.7000]),\n",
       " tensor([110.0000, 110.0000,   1.1000]),\n",
       " tensor([120.0000, 120.0000,   1.1000]),\n",
       " tensor([80.0000, 80.0000,  1.1000]),\n",
       " tensor([100.0000, 100.0000,   1.1000]),\n",
       " tensor([60.0000, 60.0000,  1.1000]),\n",
       " tensor([120.0000, 120.0000,   1.1000]),\n",
       " tensor([170.0000, 170.0000,   1.2000]),\n",
       " tensor([50.0000, 50.0000,  1.1000]),\n",
       " tensor([100.0000, 100.0000,   1.1000]),\n",
       " tensor([230.0000, 230.0000,   1.2000]),\n",
       " tensor([650.0000, 650.0000,   1.2000]),\n",
       " tensor([130.0000, 130.0000,   0.7000]),\n",
       " tensor([60.0000, 60.0000,  1.1000]),\n",
       " tensor([80.0000, 80.0000,  1.1000]),\n",
       " tensor([90.0000, 90.0000,  1.1000]),\n",
       " tensor([100.0000, 100.0000,   1.1000]),\n",
       " tensor([310.0000, 310.0000,   1.2000]),\n",
       " tensor([130., 130.,   1.]),\n",
       " tensor([350.0000, 350.0000,   1.2000]),\n",
       " tensor([100.0000, 100.0000,   1.1000]),\n",
       " tensor([180., 180.,   1.]),\n",
       " tensor([550.0000, 550.0000,   1.2000]),\n",
       " tensor([120.0000, 120.0000,   1.1000]),\n",
       " tensor([290.0000, 290.0000,   1.2000]),\n",
       " tensor([140.0000, 140.0000,   1.1000]),\n",
       " tensor([90.0000, 90.0000,  1.1000]),\n",
       " tensor([90.0000, 90.0000,  1.1000]),\n",
       " tensor([230.0000, 230.0000,   1.1000]),\n",
       " tensor([20.0000, 20.0000,  0.7000]),\n",
       " tensor([110.0000, 110.0000,   1.1000]),\n",
       " tensor([70.0000, 70.0000,  0.7000]),\n",
       " tensor([190., 190.,   1.]),\n",
       " tensor([320.0000, 320.0000,   1.2000]),\n",
       " tensor([480.0000, 480.0000,   1.2000]),\n",
       " tensor([80.0000, 80.0000,  1.1000]),\n",
       " tensor([130.0000, 130.0000,   1.1000]),\n",
       " tensor([60.0000, 60.0000,  1.1000]),\n",
       " tensor([110.0000, 110.0000,   1.1000]),\n",
       " tensor([70.0000, 70.0000,  0.7000]),\n",
       " tensor([90.0000, 90.0000,  1.1000]),\n",
       " tensor([90.0000, 90.0000,  1.1000]),\n",
       " tensor([150., 150.,   1.])]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_preds = [denormalize_decode_result(pred, max_speed, max_spacing, min_speed, min_spacing) for pred in param_preds]\n",
    "for r in decoded_preds:\n",
    "    r[0]=torch.round(r[0], decimals = -1)\n",
    "    r[1]=torch.round(r[0], decimals = 0)\n",
    "decoded_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_space = [np.arange(min_speed, max_speed + 10, 10).tolist(), np.arange(min_spacing, max_spacing + 1, 1).tolist(), np.around(np.arange(.2, 1.4, .1), decimals = 1).tolist()]\n",
    "#get set of all possible parameter combinations\n",
    "param_all_comb = set(list(itertools.product(*param_space)))\n",
    "wattages = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3]\n",
    "space_params = set([tuple(np.around(x.tolist(), decimals= 1)) for x in decoded_preds]) #29988\n",
    "        #find the combination parameters NOT in the training space\n",
    "unused_params = list(param_all_comb.intersection(space_params)) #len() = 5292\n",
    "#convert preds to set\n",
    "len(unused_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[40., 40.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [20., 20.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [40., 40.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intersecting parameters!!!!!!!\n",
    "intersect_x = []\n",
    "wattage_idxs = {\n",
    "        0.2: 0,\n",
    "        0.3: 1,\n",
    "        0.4: 2,\n",
    "        0.5: 3,\n",
    "        0.6: 4,\n",
    "        0.7: 5,\n",
    "        0.8: 6,\n",
    "        0.9: 7,\n",
    "        1.0: 8,\n",
    "        1.1: 9,\n",
    "        1.2: 10,\n",
    "        1.3: 11,\n",
    "}      \n",
    "for i in unused_params:\n",
    "        i = list(i)\n",
    "        holder = i[:2] + np.zeros(12).tolist()\n",
    "        holder[wattage_idxs[i[2]] + 2] = 1.0\n",
    "        intersect_x.append(holder)\n",
    "output = torch.tensor(intersect_x)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [20.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [40.0, 40.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12058\n",
      "19562\n",
      "19609\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(params)):\n",
    "    curr = params[i].flatten().tolist()\n",
    "    if curr in output.tolist():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import rmse\n",
    "# params[12058]\n",
    "data = torch.load(\n",
    "                Path(f\"{data_folder}/stainless-steel-revised-shuffled.pt\"))\n",
    "\n",
    "intersect_train_emiss = []\n",
    "intersect_train_emiss.append(data[\"emissivity\"][12058])\n",
    "intersect_train_emiss.append(data[\"emissivity\"][19562])\n",
    "intersect_train_emiss.append(data[\"emissivity\"][19609])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnxruntime \n",
    "# from pathlib import Path\n",
    "# import numpy as np\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session = onnxruntime.InferenceSession(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = Path(f\"{work_folder}/saved_best/best_inference_direct.onnx\")\n",
    "\n",
    "# ort_session = onnxruntime.InferenceSession(filepath)\n",
    "# input_name = ort_session.get_inputs()[0].name\n",
    "# ort_inputs = {input_name: np.random.randn(2, 14)}\n",
    "# ort_outs = ort_session.run(None, ort_inputs)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "67e7f89d5252d36c0a7a22a0bddaf9ce6b4bb105a5aa258c373ad72ae6e9c8c8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('meta')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8002f67306fdf03846a85192394013d7a0803f94603193c08381e3348b7b52be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
