{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/spencersong/metamaterials_ai/src\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if is_init:\n",
    "        pass\n",
    "except:\n",
    "    %pwd\n",
    "    %cd ..\n",
    "    %pwd\n",
    "    is_init = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from src.utils import FileUtils\n",
    "from config import Config\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from src.models import DirectModel\n",
    "from src.models import InverseModel\n",
    "from typing import List, Optional, Tuple\n",
    "from src.predictor import Predictor\n",
    "from scipy.interpolate import interp1d\n",
    "from utils import rmse\n",
    "data_folder = '../local_data'\n",
    "work_folder = '../local_work'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_params = torch.load(\n",
    "                Path(f\"{data_folder}/inconel-revised-raw-shuffled.pt\"))[\"laser_params\"]\n",
    "steel_params = torch.load(\n",
    "                Path(f\"{data_folder}/stainless-steel-revised-shuffled.pt\"))[\"laser_params\"] #stainless-steel-revised-shuffled inconel-revised-raw-shuffled\n",
    "max_speed, max_spacing = steel_params.max(0)[0][0].item(), steel_params.max(0)[0][1].item()\n",
    "min_speed, min_spacing = steel_params.min(0)[0][0].item(), steel_params.min(0)[0][1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def denormalize_decode_result(y_hat, max_speed, max_spacing, min_speed, min_spacing):\n",
    "#     \"\"\"input: 1,14 tensor\n",
    "#         output: 1,3 tensor with wattage no longer one hot encoded\"\"\"\n",
    "#     watts = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3]\n",
    "\n",
    "#     watt_arg = torch.argmax(y_hat[0][2:])\n",
    "#     y_final = torch.empty(3, dtype=torch.float32)\n",
    "#     (laser_params - laser_params.min(0).values) / (\n",
    "#         laser_params.max(0).values - laser_params.min(0).values\n",
    "#     )\n",
    "#     y_final[0] = ((max_speed - min_speed) * y_hat[0][0]) + min_speed # TODO call the scale\n",
    "#     y_final[1] = ((max_spacing-min_spacing) * y_hat[0][1]) + min_spacing # TODO call the scale\n",
    "#     y_final[2]= watts[watt_arg]\n",
    "#     return y_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(csv):\n",
    "    num_wavelens = 800\n",
    "    emiss_plot = [item[1][1] for item in read_file.iterrows() if (item[1][1] != 1.0 and item[1][0] < 12)]\n",
    "    wavelength_plot = [item[1][0] for item in read_file.iterrows() if (item[1][1] != 1.0 and item[1][0] < 12)]\n",
    "\n",
    "    # Reverse to sort in ascending rather than descending order.\n",
    "    # emiss_plot.reverse()\n",
    "    # wavelength_plot.reverse()\n",
    "\n",
    "    interp_wavelen = np.linspace(\n",
    "                min(wavelength_plot), max(wavelength_plot), num=num_wavelens\n",
    "            )\n",
    "    interp_emiss = interp1d(wavelength_plot, emiss_plot)(interp_wavelen).astype(np.float32).reshape(1, 800)\n",
    "    predictor_input = torch.from_numpy(interp_emiss)\n",
    "    return predictor_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_file\n",
    "read_file = pd.read_csv('../src/notebooks/sample_input.csv')\n",
    "desired_emiss = interpolate(read_file) #torch.from_numpy(np.array(torch.randn(1, 800) * 3))\n",
    "include_inconel = False #Change ME\n",
    "include_stainless = True #Change ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/spencersong/metamaterials_ai/src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:217: UserWarning: Found keys that are not in the model state dict but in the checkpoint: ['direct_model.model.0.weight', 'direct_model.model.0.bias', 'direct_model.model.2.layers.0.block.0.weight', 'direct_model.model.2.layers.0.block.0.bias', 'direct_model.model.2.layers.1.block.0.weight', 'direct_model.model.2.layers.1.block.0.bias', 'direct_model.model.2.layers.2.block.0.weight', 'direct_model.model.2.layers.2.block.0.bias', 'direct_model.model.2.layers.3.block.0.weight', 'direct_model.model.2.layers.3.block.0.bias', 'direct_model.model.2.layers.4.block.0.weight', 'direct_model.model.2.layers.4.block.0.bias', 'direct_model.model.2.layers.5.block.0.weight', 'direct_model.model.2.layers.5.block.0.bias', 'direct_model.model.2.layers.6.block.0.weight', 'direct_model.model.2.layers.6.block.0.bias', 'direct_model.model.2.layers.7.block.0.weight', 'direct_model.model.2.layers.7.block.0.bias', 'direct_model.model.2.layers.8.block.0.weight', 'direct_model.model.2.layers.8.block.0.bias', 'direct_model.model.2.layers.9.block.0.weight', 'direct_model.model.2.layers.9.block.0.bias', 'direct_model.model.2.layers.10.block.0.weight', 'direct_model.model.2.layers.10.block.0.bias', 'direct_model.model.2.layers.11.block.0.weight', 'direct_model.model.2.layers.11.block.0.bias', 'direct_model.model.2.layers.12.block.0.weight', 'direct_model.model.2.layers.12.block.0.bias', 'direct_model.model.2.layers.13.block.0.weight', 'direct_model.model.2.layers.13.block.0.bias', 'direct_model.model.2.layers.14.block.0.weight', 'direct_model.model.2.layers.14.block.0.bias', 'direct_model.model.2.layers.15.block.0.weight', 'direct_model.model.2.layers.15.block.0.bias', 'direct_model.model.3.weight', 'direct_model.model.3.bias']\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "predictor = Predictor(desired_emiss, True, True)\n",
    "y_hat_ss, y_hat_inc = predictor.run_inverse(predictor.desired)\n",
    "direct_ss_emiss_y_hat, direct_inc_emiss_y_hat = predictor.run_direct(y_hat_ss, y_hat_inc)\n",
    "best_substrate, best_params, best_rmse = predictor.best_predictor(True, True, direct_ss_emiss_y_hat, direct_inc_emiss_y_hat, predictor.desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stainless [577.7000122070312, 34.29999923706055, 0.20000000298023224] 0.05857977271080017\n"
     ]
    }
   ],
   "source": [
    "#outputs of ensemble!!\n",
    "print(best_substrate, best_params, best_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Model Only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../local_work/saved_best/I-0.9-res-ann-stainless.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:217: UserWarning: Found keys that are not in the model state dict but in the checkpoint: ['direct_model.model.0.weight', 'direct_model.model.0.bias', 'direct_model.model.2.layers.0.block.0.weight', 'direct_model.model.2.layers.0.block.0.bias', 'direct_model.model.2.layers.1.block.0.weight', 'direct_model.model.2.layers.1.block.0.bias', 'direct_model.model.2.layers.2.block.0.weight', 'direct_model.model.2.layers.2.block.0.bias', 'direct_model.model.2.layers.3.block.0.weight', 'direct_model.model.2.layers.3.block.0.bias', 'direct_model.model.2.layers.4.block.0.weight', 'direct_model.model.2.layers.4.block.0.bias', 'direct_model.model.2.layers.5.block.0.weight', 'direct_model.model.2.layers.5.block.0.bias', 'direct_model.model.2.layers.6.block.0.weight', 'direct_model.model.2.layers.6.block.0.bias', 'direct_model.model.2.layers.7.block.0.weight', 'direct_model.model.2.layers.7.block.0.bias', 'direct_model.model.2.layers.8.block.0.weight', 'direct_model.model.2.layers.8.block.0.bias', 'direct_model.model.2.layers.9.block.0.weight', 'direct_model.model.2.layers.9.block.0.bias', 'direct_model.model.2.layers.10.block.0.weight', 'direct_model.model.2.layers.10.block.0.bias', 'direct_model.model.2.layers.11.block.0.weight', 'direct_model.model.2.layers.11.block.0.bias', 'direct_model.model.2.layers.12.block.0.weight', 'direct_model.model.2.layers.12.block.0.bias', 'direct_model.model.2.layers.13.block.0.weight', 'direct_model.model.2.layers.13.block.0.bias', 'direct_model.model.2.layers.14.block.0.weight', 'direct_model.model.2.layers.14.block.0.bias', 'direct_model.model.2.layers.15.block.0.weight', 'direct_model.model.2.layers.15.block.0.bias', 'direct_model.model.3.weight', 'direct_model.model.3.bias']\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "x = desired_emiss\n",
    "\n",
    "if include_inconel:\n",
    "    inverse_ss_filepath = Path(f\"{work_folder}/saved_best/I-0.9-res-ann-stainless.ckpt\") #CHANGEME\n",
    "    print(inverse_ss_filepath)\n",
    "    if not Path.is_file(inverse_ss_filepath):\n",
    "        raise Exception(f'Model file does not exist at {inverse_ss_filepath}!')\n",
    "\n",
    "    i_model_ss = InverseModel.load_from_checkpoint(inverse_ss_filepath, strict=False)\n",
    "    i_model_ss.eval()\n",
    "    with torch.no_grad():\n",
    "        y_hat_ss = i_model_ss(x)\n",
    "    #y_hat_ss_clean = denormalize_decode_result(y_hat_ss, max_speed, max_spacing, min_speed, min_spacing)\n",
    "\n",
    "if include_stainless:\n",
    "    inverse_inc_filepath = Path(f\"{work_folder}/saved_best/I-0.9-res-ann-inconel.ckpt\") #CHANGEME\n",
    "    print(inverse_inc_filepath)\n",
    "    if not Path.is_file(inverse_inc_filepath):\n",
    "        raise Exception(f'Model file does not exist at {inverse_inc_filepath}!')\n",
    "\n",
    "    i_model_inc = InverseModel.load_from_checkpoint(inverse_inc_filepath, strict=False)\n",
    "    i_model_inc.eval()\n",
    "    with torch.no_grad():\n",
    "        y_hat_inc = i_model_inc(x)\n",
    "    #y_hat_inc_clean = denormalize_decode_result(y_hat_inc, max_speed, max_spacing, min_speed, min_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_final2 = onehot_to_continuous2(y_hat)\n",
    "#print(denormalize_decode_result(y_hat,max_speed, max_spacing, min_speed, min_spacing))\n",
    "\n",
    "#if you want hardcoded max, min values instead\n",
    "#print(denormalize_decode_result(y_hat,700.0, 42.0, 10.0, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Ensemble with Direct Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../local_work/saved_best/D-0.9-res-ann-stainless.ckpt\n",
      "../local_work/saved_best/D-0.9-res-ann-inconel.ckpt\n"
     ]
    }
   ],
   "source": [
    "from src.models import DirectModel\n",
    "\n",
    "direct_ss_filepath = Path(\"\"\n",
    "    f\"{work_folder}/saved_best/D-0.9-res-ann-stainless.ckpt\") #CHANGEME\n",
    "print(direct_ss_filepath)\n",
    "if not Path.is_file(direct_ss_filepath):\n",
    "    raise Exception(f'Model file does not exist at {direct_ss_filepath}!')\n",
    "\n",
    "direct_inc_filepath = Path(\"\"\n",
    "    f\"{work_folder}/saved_best/D-0.9-res-ann-inconel.ckpt\") #CHANGEME\n",
    "print(direct_inc_filepath)\n",
    "if not Path.is_file(direct_inc_filepath):\n",
    "    raise Exception(f'Model file does not exist at {direct_inc_filepath}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if include_stainless:\n",
    "    d_ss_model = DirectModel.load_from_checkpoint(direct_ss_filepath)\n",
    "    d_ss_model.eval()\n",
    "    # x = torch.randn(1, 14)\n",
    "    # intersect_preds = []\n",
    "    with torch.no_grad():\n",
    "        direct_ss_emiss_y_hat = d_ss_model(y_hat_ss.reshape(1,14))\n",
    "        \n",
    "if include_inconel:\n",
    "    d_inc_model = DirectModel.load_from_checkpoint(direct_inc_filepath)\n",
    "    d_inc_model.eval()\n",
    "    # x = torch.randn(1, 14)\n",
    "    # intersect_preds = []\n",
    "    with torch.no_grad():\n",
    "        direct_inc_emiss_y_hat = d_inc_model(y_hat_ss.reshape(1,14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Best Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "substrates = ['inconel', 'stainless']\n",
    "best_params = []\n",
    "best_rmse = 0\n",
    "if include_inconel and include_stainless:\n",
    "    if rmse(direct_inc_emiss_y_hat, desired_emiss) < rmse(direct_ss_emiss_y_hat, desired_emiss):\n",
    "        best_substrate = substrates[0]\n",
    "        best_params = denormalize_decode_result(y_hat_inc, max_speed, max_spacing, min_speed, min_spacing)\n",
    "        best_rmse = rmse(direct_inc_emiss_y_hat, desired_emiss).item()\n",
    "    else:\n",
    "        best_substrate = substrates[1]\n",
    "        best_params = denormalize_decode_result(y_hat_ss, max_speed, max_spacing, min_speed, min_spacing)\n",
    "        best_rmse = rmse(direct_ss_emiss_y_hat, desired_emiss).item()\n",
    "elif include_inconel:\n",
    "    best_substrate = substrates[0]\n",
    "    best_params = denormalize_decode_result(y_hat_inc, max_speed, max_spacing, min_speed, min_spacing)\n",
    "    best_rmse = rmse(direct_inc_emiss_y_hat, desired_emiss).item()\n",
    "else:\n",
    "    best_substrate = substrates[1]\n",
    "    best_params = denormalize_decode_result(y_hat_ss, max_speed, max_spacing, min_speed, min_spacing)\n",
    "    best_rmse = rmse(direct_ss_emiss_y_hat, desired_emiss).item()\n",
    "\n",
    "best_params = [torch.round(best_params[0], decimals = 1).item(), torch.round(best_params[1], decimals = 1).item(), torch.round(best_params[2], decimals = 1).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inconel\n",
      "[91.69999694824219, 0.20000000298023224, 0.4000000059604645]\n",
      "3.0110976696014404\n"
     ]
    }
   ],
   "source": [
    "print(best_substrate)\n",
    "print(best_params)\n",
    "print(best_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.load(\n",
    "                Path(f\"{data_folder}/inconel-revised-raw-shuffled.pt\"))[\"laser_params\"] #stainless-steel-revised-shuffled inconel-revised-raw-shuffled\n",
    "max_speed, max_spacing = params.max(0)[0][0].item(), params.max(0)[0][1].item()\n",
    "min_speed, min_spacing = params.min(0)[0][0].item(), params.min(0)[0][1].item()\n",
    "decoded_preds = [denormalize_decode_result(pred, max_speed, max_spacing, min_speed, min_spacing) for pred in param_preds]\n",
    "for r in decoded_preds:\n",
    "    r[0]=torch.round(r[0], decimals = -1)\n",
    "    r[1]=torch.round(r[1], decimals = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591\n",
      "352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_space = [np.arange(min_speed, max_speed + 10, 10).tolist(), np.arange(min_spacing, max_spacing + 1, 1).tolist(), np.around(np.arange(.2, 1.4, .1), decimals = 1).tolist()]\n",
    "#get set of all possible parameter combinations\n",
    "param_all_comb = set(list(itertools.product(*param_space)))\n",
    "wattages = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3]\n",
    "space_params = set([tuple(np.around(x.tolist(), decimals= 1)) for x in decoded_preds]) #29988\n",
    "        #find the combination parameters NOT in the training space\n",
    "overlaps = list(param_all_comb.intersection(space_params)) #len() = 5292\n",
    "unused_params = list(set(overlaps).symmetric_difference(space_params)) #len() = 5292\n",
    "#convert preds to set\n",
    "print(len(space_params))\n",
    "print(len(overlaps)) #332\n",
    "len(unused_params) #216\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(570.0, 13.0, 1.2),\n",
       " (330.0, 13.0, 1.2),\n",
       " (610.0, 14.0, 1.2),\n",
       " (340.0, 10.0, 1.2),\n",
       " (550.0, 11.0, 1.2),\n",
       " (510.0, 9.0, 1.2),\n",
       " (500.0, 7.0, 1.2),\n",
       " (660.0, 9.0, 1.2),\n",
       " (370.0, 12.0, 1.2),\n",
       " (440.0, 9.0, 1.2),\n",
       " (650.0, 10.0, 1.2),\n",
       " (490.0, 13.0, 1.2),\n",
       " (220.0, 12.0, 1.2),\n",
       " (610.0, 13.0, 1.2),\n",
       " (420.0, 7.0, 1.2),\n",
       " (180.0, 10.0, 1.2),\n",
       " (640.0, 8.0, 1.2),\n",
       " (470.0, 11.0, 1.2),\n",
       " (460.0, 8.0, 1.2),\n",
       " (340.0, 13.0, 1.2),\n",
       " (510.0, 12.0, 1.2),\n",
       " (580.0, 9.0, 1.2),\n",
       " (100.0, 10.0, 1.2),\n",
       " (280.0, 9.0, 1.2),\n",
       " (260.0, 11.0, 1.2),\n",
       " (450.0, 14.0, 1.2),\n",
       " (630.0, 13.0, 1.2),\n",
       " (440.0, 12.0, 1.2),\n",
       " (140.0, 12.0, 1.2),\n",
       " (420.0, 10.0, 1.2),\n",
       " (360.0, 10.0, 1.2),\n",
       " (670.0, 11.0, 0.5),\n",
       " (170.0, 8.0, 1.2),\n",
       " (100.0, 13.0, 1.2),\n",
       " (380.0, 9.0, 1.2),\n",
       " (520.0, 12.0, 1.2),\n",
       " (500.0, 10.0, 1.2),\n",
       " (160.0, 14.0, 1.2),\n",
       " (200.0, 10.0, 1.2),\n",
       " (550.0, 14.0, 1.2),\n",
       " (620.0, 11.0, 1.2),\n",
       " (130.0, 9.0, 1.2),\n",
       " (360.0, 13.0, 1.2),\n",
       " (480.0, 13.0, 1.2),\n",
       " (640.0, 11.0, 1.2),\n",
       " (0.0, 28.0, 0.8),\n",
       " (180.0, 13.0, 1.2),\n",
       " (600.0, 9.0, 1.2),\n",
       " (570.0, 8.0, 1.2),\n",
       " (460.0, 11.0, 1.2),\n",
       " (650.0, 13.0, 1.2),\n",
       " (300.0, 14.0, 1.2),\n",
       " (390.0, 9.0, 1.2),\n",
       " (280.0, 12.0, 1.2),\n",
       " (670.0, 7.0, 1.2),\n",
       " (400.0, 13.0, 1.2),\n",
       " (610.0, 8.0, 1.2),\n",
       " (380.0, 11.0, 1.2),\n",
       " (540.0, 12.0, 1.2),\n",
       " (660.0, 12.0, 1.2),\n",
       " (400.0, 14.0, 1.2),\n",
       " (510.0, 7.0, 1.2),\n",
       " (590.0, 7.0, 1.2),\n",
       " (380.0, 12.0, 1.2),\n",
       " (500.0, 13.0, 1.2),\n",
       " (590.0, 8.0, 1.2),\n",
       " (620.0, 14.0, 1.2),\n",
       " (130.0, 12.0, 1.2),\n",
       " (320.0, 14.0, 1.2),\n",
       " (600.0, 12.0, 1.2),\n",
       " (530.0, 9.0, 1.2),\n",
       " (230.0, 9.0, 1.2),\n",
       " (520.0, 7.0, 1.2),\n",
       " (580.0, 13.0, 1.2),\n",
       " (90.0, 12.0, 1.2),\n",
       " (560.0, 11.0, 1.2),\n",
       " (430.0, 13.0, 1.2),\n",
       " (630.0, 8.0, 1.2),\n",
       " (370.0, 10.0, 1.2),\n",
       " (550.0, 9.0, 1.2),\n",
       " (330.0, 8.0, 1.2),\n",
       " (210.0, 13.0, 1.2),\n",
       " (360.0, 8.0, 1.2),\n",
       " (420.0, 14.0, 1.2),\n",
       " (480.0, 8.0, 1.2),\n",
       " (490.0, 11.0, 1.2),\n",
       " (250.0, 14.0, 1.2),\n",
       " (190.0, 11.0, 1.2),\n",
       " (530.0, 12.0, 1.2),\n",
       " (470.0, 9.0, 1.2),\n",
       " (650.0, 8.0, 1.2),\n",
       " (310.0, 12.0, 1.2),\n",
       " (510.0, 10.0, 1.2),\n",
       " (170.0, 14.0, 1.2),\n",
       " (350.0, 13.0, 1.2),\n",
       " (630.0, 11.0, 1.2),\n",
       " (640.0, 14.0, 1.2),\n",
       " (570.0, 11.0, 1.2),\n",
       " (330.0, 11.0, 1.2),\n",
       " (460.0, 14.0, 1.2),\n",
       " (450.0, 12.0, 1.2),\n",
       " (190.0, 14.0, 1.2),\n",
       " (660.0, 7.0, 1.2),\n",
       " (670.0, 10.0, 1.2),\n",
       " (470.0, 12.0, 1.2),\n",
       " (90.0, 14.0, 1.2),\n",
       " (560.0, 13.0, 1.2),\n",
       " (590.0, 13.0, 1.2),\n",
       " (520.0, 10.0, 1.2),\n",
       " (110.0, 14.0, 1.2),\n",
       " (500.0, 8.0, 1.2),\n",
       " (160.0, 12.0, 1.2),\n",
       " (340.0, 11.0, 1.2),\n",
       " (80.0, 13.0, 1.2),\n",
       " (550.0, 12.0, 1.2),\n",
       " (230.0, 14.0, 1.2),\n",
       " (620.0, 9.0, 1.2),\n",
       " (600.0, 7.0, 1.2),\n",
       " (370.0, 13.0, 1.2),\n",
       " (650.0, 11.0, 1.2),\n",
       " (300.0, 12.0, 1.2),\n",
       " (580.0, 8.0, 1.2),\n",
       " (390.0, 7.0, 1.2),\n",
       " (120.0, 13.0, 1.2),\n",
       " (630.0, 14.0, 1.2),\n",
       " (670.0, 9.0, 0.5),\n",
       " (420.0, 9.0, 1.2),\n",
       " (100.0, 11.0, 1.2),\n",
       " (120.0, 14.0, 1.2),\n",
       " (540.0, 10.0, 1.2),\n",
       " (660.0, 10.0, 1.2),\n",
       " (170.0, 9.0, 1.2),\n",
       " (520.0, 13.0, 1.2),\n",
       " (480.0, 11.0, 1.2),\n",
       " (560.0, 9.0, 1.2),\n",
       " (220.0, 13.0, 1.2),\n",
       " (640.0, 9.0, 1.2),\n",
       " (570.0, 6.0, 1.2),\n",
       " (340.0, 14.0, 1.2),\n",
       " (620.0, 12.0, 1.2),\n",
       " (510.0, 13.0, 1.2),\n",
       " (660.0, 13.0, 1.2),\n",
       " (410.0, 7.0, 1.2),\n",
       " (600.0, 10.0, 1.2),\n",
       " (560.0, 8.0, 1.2),\n",
       " (440.0, 13.0, 1.2),\n",
       " (650.0, 14.0, 1.2),\n",
       " (580.0, 11.0, 1.2),\n",
       " (420.0, 11.0, 1.2),\n",
       " (570.0, 9.0, 1.2),\n",
       " (350.0, 8.0, 1.2),\n",
       " (400.0, 12.0, 1.2),\n",
       " (550.0, 7.0, 1.2),\n",
       " (670.0, 12.0, 0.5),\n",
       " (210.0, 11.0, 1.2),\n",
       " (100.0, 14.0, 1.2),\n",
       " (670.0, 8.0, 1.2),\n",
       " (540.0, 13.0, 1.2),\n",
       " (500.0, 11.0, 1.2),\n",
       " (310.0, 10.0, 1.2),\n",
       " (610.0, 9.0, 1.2),\n",
       " (480.0, 14.0, 1.2),\n",
       " (290.0, 8.0, 1.2),\n",
       " (470.0, 7.0, 1.2),\n",
       " (640.0, 12.0, 1.2),\n",
       " (180.0, 14.0, 1.2),\n",
       " (460.0, 12.0, 1.2),\n",
       " (610.0, 10.0, 1.2),\n",
       " (380.0, 13.0, 1.2),\n",
       " (450.0, 10.0, 1.2),\n",
       " (390.0, 10.0, 1.2),\n",
       " (150.0, 10.0, 1.2),\n",
       " (680.0, 8.0, 0.5),\n",
       " (280.0, 13.0, 1.2),\n",
       " (310.0, 13.0, 1.2),\n",
       " (130.0, 13.0, 1.2),\n",
       " (680.0, 9.0, 0.5),\n",
       " (70.0, 13.0, 1.2),\n",
       " (220.0, 8.0, 1.2),\n",
       " (600.0, 13.0, 1.2),\n",
       " (570.0, 12.0, 1.2),\n",
       " (530.0, 10.0, 1.2),\n",
       " (340.0, 9.0, 1.2),\n",
       " (110.0, 12.0, 1.2),\n",
       " (620.0, 7.0, 1.2),\n",
       " (510.0, 8.0, 1.2),\n",
       " (630.0, 9.0, 1.2),\n",
       " (370.0, 11.0, 1.2),\n",
       " (650.0, 9.0, 1.2),\n",
       " (610.0, 12.0, 1.2),\n",
       " (350.0, 14.0, 1.2),\n",
       " (470.0, 10.0, 1.2),\n",
       " (590.0, 11.0, 1.2),\n",
       " (520.0, 8.0, 1.2),\n",
       " (260.0, 10.0, 1.2),\n",
       " (450.0, 13.0, 1.2)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#send these to minok\n",
    "count_samples_to_minok = 196\n",
    "unused_params[:count_samples_to_minok]#overlaps)\n",
    "#overlaps[:195]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[600.,  34.,   0.,  ...,   0.,   0.,   0.],\n",
       "        [590.,  14.,   0.,  ...,   0.,   1.,   0.],\n",
       "        [580.,  31.,   0.,  ...,   0.,   0.,   0.],\n",
       "        ...,\n",
       "        [640.,  16.,   0.,  ...,   0.,   1.,   0.],\n",
       "        [520.,  38.,   0.,  ...,   0.,   0.,   0.],\n",
       "        [300.,  37.,   0.,  ...,   0.,   0.,   0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intersecting parameters!!!!!!!\n",
    "intersect_x = []\n",
    "wattage_idxs = {\n",
    "        0.2: 0,\n",
    "        0.3: 1,\n",
    "        0.4: 2,\n",
    "        0.5: 3,\n",
    "        0.6: 4,\n",
    "        0.7: 5,\n",
    "        0.8: 6,\n",
    "        0.9: 7,\n",
    "        1.0: 8,\n",
    "        1.1: 9,\n",
    "        1.2: 10,\n",
    "        1.3: 11,\n",
    "}      \n",
    "for i in unused_params:\n",
    "        i = list(i)\n",
    "        holder = i[:2] + np.zeros(12).tolist()\n",
    "        holder[wattage_idxs[i[2]] + 2] = 1.0\n",
    "        intersect_x.append(holder)\n",
    "output = torch.tensor(intersect_x)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12058\n",
      "19562\n",
      "19609\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(params)):\n",
    "    curr = params[i].flatten().tolist()\n",
    "    if curr in output.tolist():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import rmse\n",
    "# params[12058]\n",
    "data = torch.load(\n",
    "                Path(f\"{data_folder}/stainless-steel-revised-shuffled.pt\"))\n",
    "\n",
    "intersect_train_emiss = []\n",
    "intersect_train_emiss.append(data[\"emissivity\"][12058])\n",
    "intersect_train_emiss.append(data[\"emissivity\"][19562])\n",
    "intersect_train_emiss.append(data[\"emissivity\"][19609])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnxruntime \n",
    "# from pathlib import Path\n",
    "# import numpy as np\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session = onnxruntime.InferenceSession(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = Path(f\"{work_folder}/saved_best/best_inference_direct.onnx\")\n",
    "\n",
    "# ort_session = onnxruntime.InferenceSession(filepath)\n",
    "# input_name = ort_session.get_inputs()[0].name\n",
    "# ort_inputs = {input_name: np.random.randn(2, 14)}\n",
    "# ort_outs = ort_session.run(None, ort_inputs)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "67e7f89d5252d36c0a7a22a0bddaf9ce6b4bb105a5aa258c373ad72ae6e9c8c8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('meta')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8002f67306fdf03846a85192394013d7a0803f94603193c08381e3348b7b52be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
