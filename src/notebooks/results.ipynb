{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if is_init:\n",
    "        pass\n",
    "except:\n",
    "    %pwd\n",
    "    %cd ..\n",
    "    %pwd\n",
    "    is_init = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from src.utils import FileUtils\n",
    "from config import Config\n",
    "from utils import rmse\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from src.predictor import Predictor\n",
    "import random\n",
    "import itertools\n",
    "data_folder = '../local_data'\n",
    "work_folder = '../local_work'\n",
    "configs_folder = '../configs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_params = torch.load(\n",
    "                Path(f\"{data_folder}/inconel.pt\"))[\"laser_params\"]\n",
    "steel_params = torch.load(\n",
    "                Path(f\"{data_folder}/stainless.pt\"))[\"laser_params\"] #stainless-steel-revised-shuffled inconel-revised-raw-shuffled\n",
    "max_speed, max_spacing = steel_params.max(0)[0][0].item(), steel_params.max(0)[0][1].item()\n",
    "min_speed, min_spacing = steel_params.min(0)[0][0].item(), steel_params.min(0)[0][1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_file\n",
    "# read_file = pd.read_csv('../src/notebooks/sample_input.csv')\n",
    "# desired_emiss = interpolate(read_file) #torch.from_numpy(np.array(torch.randn(1, 800) * 3))\n",
    "\n",
    "include_inconel = False #Change ME\n",
    "include_stainless = True #Change ME\n",
    "round_laser_params = False #Change Me\n",
    "\n",
    "def get_test_data(filepath):\n",
    "    stain_data = torch.load(\n",
    "                    Path(filepath))#[\"laser_params\"] #stainless-steel-revised-shuffled inconel-revised-raw-shuffled\n",
    "    wave_data = stain_data[\"interpolated_wavelength\"]\n",
    "    emiss_data = stain_data[\"interpolated_emissivity\"]\n",
    "    laser_params = stain_data[\"laser_params\"]\n",
    "    wave_test = wave_data[round(len(wave_data) * .9):]  \n",
    "    emiss_test = emiss_data[round(len(wave_data) * .9):]\n",
    "    laser_params = laser_params[round(len(wave_data) * .9):]\n",
    "    return wave_test, emiss_test, laser_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/spencersong/metamaterials_ai/src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/home/spencersong/anaconda3/envs/meta/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:217: UserWarning: Found keys that are not in the model state dict but in the checkpoint: ['direct_model.model.0.weight', 'direct_model.model.0.bias', 'direct_model.model.2.layers.0.block.0.weight', 'direct_model.model.2.layers.0.block.0.bias', 'direct_model.model.2.layers.1.block.0.weight', 'direct_model.model.2.layers.1.block.0.bias', 'direct_model.model.2.layers.2.block.0.weight', 'direct_model.model.2.layers.2.block.0.bias', 'direct_model.model.2.layers.3.block.0.weight', 'direct_model.model.2.layers.3.block.0.bias', 'direct_model.model.2.layers.4.block.0.weight', 'direct_model.model.2.layers.4.block.0.bias', 'direct_model.model.2.layers.5.block.0.weight', 'direct_model.model.2.layers.5.block.0.bias', 'direct_model.model.2.layers.6.block.0.weight', 'direct_model.model.2.layers.6.block.0.bias', 'direct_model.model.2.layers.7.block.0.weight', 'direct_model.model.2.layers.7.block.0.bias', 'direct_model.model.2.layers.8.block.0.weight', 'direct_model.model.2.layers.8.block.0.bias', 'direct_model.model.2.layers.9.block.0.weight', 'direct_model.model.2.layers.9.block.0.bias', 'direct_model.model.2.layers.10.block.0.weight', 'direct_model.model.2.layers.10.block.0.bias', 'direct_model.model.2.layers.11.block.0.weight', 'direct_model.model.2.layers.11.block.0.bias', 'direct_model.model.2.layers.12.block.0.weight', 'direct_model.model.2.layers.12.block.0.bias', 'direct_model.model.2.layers.13.block.0.weight', 'direct_model.model.2.layers.13.block.0.bias', 'direct_model.model.2.layers.14.block.0.weight', 'direct_model.model.2.layers.14.block.0.bias', 'direct_model.model.2.layers.15.block.0.weight', 'direct_model.model.2.layers.15.block.0.bias', 'direct_model.model.3.weight', 'direct_model.model.3.bias']\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "wave_test, emiss_test, laser_params = get_test_data(f\"{data_folder}/stainless.pt\")\n",
    "# for emiss in emiss_test:\n",
    "predictor = Predictor(emiss_test[0].reshape(1,800), include_inconel, include_stainless, round_laser_params = True)\n",
    "y_hat_ss, y_hat_inc = predictor.run_inverse(predictor.desired)\n",
    "#predictor.denormalize_decode_result()\n",
    "    # direct_ss_emiss_y_hat, direct_inc_emiss_y_hat = predictor.run_direct(y_hat_ss, y_hat_inc)\n",
    "    # best_substrate, best_params, best_rmse = predictor.best_predictor(True, True, direct_ss_emiss_y_hat, direct_inc_emiss_y_hat, predictor.desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[40., 42.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_final = predictor.denorm_result(y_hat_ss, predictor.ss_max_speed, predictor.ss_max_spacing, predictor.ss_min_speed, predictor.ss_min_spacing)\n",
    "y_final\n",
    "#y_hat_ss[0] = torch.round(y_hat_ss[0], decimals = -1)\n",
    "#y_hat_ss[1] = torch.round(y_hat_ss[1], decimals = 0)\n",
    "#y_hat_ss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13998"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stain_data = torch.load(\n",
    "#                     Path(filepath))#[\"laser_params\"] #stainless-steel-revised-shuffled inconel-revised-raw-shuffled\n",
    "# wave_data = stain_data[\"interpolated_wavelength\"]\n",
    "# emiss_data = stain_data[\"interpolated_emissivity\"]\n",
    "# laser_params = stain_data[\"laser_params\"]\n",
    "# def check_params_in_data(filepath):\n",
    "#     stain_data = torch.load(\n",
    "#                     Path(filepath))#[\"laser_params\"] #stainless-steel-revised-shuffled inconel-revised-raw-shuffled\n",
    "#     wave_data = stain_data[\"interpolated_wavelength\"]\n",
    "#     emiss_data = stain_data[\"interpolated_emissivity\"]\n",
    "#     laser_params = stain_data[\"laser_params\"]\n",
    "    \n",
    "#     return wave_test, emiss_test, laser_params\n",
    "# laser_params\n",
    "#torch.nonzero(y_final[0] == steel_params.sum(dim=1)==steel_params.size(1))\n",
    "i = 0\n",
    "found_index = -1\n",
    "for comb in steel_params:\n",
    "    i += 1\n",
    "    if torch.all(torch.eq(comb, y_final)):\n",
    "        found_index = i\n",
    "#y_final in steel_params\n",
    "\n",
    "found_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['wavelength', 'laser_params', 'emissivity', 'uids', 'interpolated_emissivity', 'interpolated_wavelength', 'normalized_laser_params'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inc_params = torch.load(\n",
    "#                 Path(f\"{data_folder}/inconel-revised-raw-shuffled.pt\"))[\"emissivity\"]\n",
    "steel_emiss = torch.load(Path(f\"{data_folder}/stainless.pt\"))#[\"emissivity\"]\n",
    "\n",
    "steel_emiss.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([130.,  41.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          1.,   0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steel_params[0]#[30380]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.isin()y_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_in_data(self, rounded_y_hat, ):\n",
    "        indices_have_in_data\n",
    "        indices_not_have_in_data\n",
    "        return rounded_y_hat, indices_have_in_data, indeces_not_have_in_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_ss_filepath = Path(f\"{work_folder}/saved_best/I-1-res-ann-stainless.ckpt\") #CHANGEME\n",
    "inverse_inc_filepath = Path(f\"{work_folder}/saved_best/I-1-res-ann-inconel.ckpt\") #CHANGEME\n",
    "print(inverse_ss_filepath)\n",
    "print(inverse_inc_filepath)\n",
    "if not Path.is_file(inverse_ss_filepath):\n",
    "    raise Exception(f'Model file does not exist at {inverse_ss_filepath}!')\n",
    "if not Path.is_file(inverse_inc_filepath):\n",
    "    raise Exception(f'Model file does not exist at {inverse_inc_filepath}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(filepath):\n",
    "    stain_data = torch.load(\n",
    "                    Path(f\"{data_folder}/{filepath}\"))#[\"laser_params\"] #stainless-steel-revised-shuffled inconel-revised-raw-shuffled\n",
    "    wave_data = stain_data[\"interpolated_wavelength\"]\n",
    "    emiss_data = stain_data[\"interpolated_emissivity\"]\n",
    "    laser_params = stain_data[\"laser_params\"]#.keys()#[\"wavelenght\"]\n",
    "    #print(wave_test.max(1), wave_test.min(1)) #2.5002, 11.9479\n",
    "    #print(emiss_test.max(1)[0])#.max(1), emiss_test.min(1)) #0, 1\n",
    "    wave_test = wave_data[round(len(wave_data) * .9):]  \n",
    "    emiss_test = emiss_data[round(len(wave_data) * .9):]\n",
    "    return wave_test, emiss_test, laser_params\n",
    "#print(max_wave, min_wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass test data into inverse model, get predicted parameters\n",
    "from src.models import InverseModel\n",
    "i_model = InverseModel.load_from_checkpoint(inverse_ss_filepath, strict=False)\n",
    "i_model.eval()\n",
    "\n",
    "wave_test, emiss_test, laser_params = get_test_data('stainless-steel-revised-shuffled.pt')\n",
    "\n",
    "test_y_hats = []#torch.empty(size = len(emiss_test))\n",
    "for emiss in emiss_test:\n",
    "    with torch.no_grad():\n",
    "        test_y_hats.append(i_model(emiss.reshape(1, 800)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laser_test = laser_params\n",
    "max_speed, max_spacing = laser_test.max(0)[0][0].item(), laser_test.max(0)[0][1].item()\n",
    "min_speed, min_spacing = laser_test.min(0)[0][0].item(), laser_test.min(0)[0][1].item()\n",
    "laser_output = [denormalize_decode_result(x.reshape(1,14), max_speed, max_spacing, min_speed, min_spacing) for x in laser_test]\n",
    "\n",
    "# denormalize_decode_result(laser_test[3].reshape(1,14),max_speed, max_spacing, min_speed, min_spacing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import DirectModel\n",
    "direct_filepath = Path(\"\"\n",
    "    f\"{work_folder}/saved_best/D-1-res-ann-stainless.ckpt\") #CHANGEME\n",
    "print(direct_filepath)\n",
    "if not Path.is_file(direct_filepath):\n",
    "    raise Exception(f'Model file does not exist at {direct_filepath}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = DirectModel.load_from_checkpoint(direct_filepath)\n",
    "d_model.eval()\n",
    "emiss_y_hats = []\n",
    "for x in test_y_hats:\n",
    "    with torch.no_grad():\n",
    "        emiss_y_hats.append(d_model(x.reshape(1,14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate rmse\n",
    "pred_rmse_vals = []\n",
    "columns = [\"wavelength\", \"emissivity\", \"prediction\", \"example_number\", \"laser_params\"]\n",
    "viz_coords = pd.DataFrame(columns = columns)\n",
    "for i in range(9):#len(emiss_test)):\n",
    "    pred_rmse_vals.append(rmse(emiss_y_hats[i], emiss_test[i]).item())\n",
    "    for j in range(len(wave_test[i].tolist())):\n",
    "        viz_coords.append([wave_test[i].tolist()[j], emiss_test[i].tolist()[j], \"True\", i, laser_output[i].tolist()])\n",
    "        viz_coords.append([wave_test[i].tolist()[j], emiss_y_hats[i].flatten().tolist()[j], \"Prediction\", i, laser_output[i].tolist()])\n",
    "stdev = np.std(pred_rmse_vals)\n",
    "print(f'Direct Filepath: {direct_filepath}')\n",
    "print(f'Inverse Filepath: {inverse_ss_filepath}')\n",
    "print(f'SD of RMSEs on test data: {stdev}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(viz_coords).mark_line().encode(\n",
    "    x='wavelength',\n",
    "    y='emissivity'\n",
    ").facet(facet = 'example_number:N')#, header = 'laser_params:N')#.encode(text = 'laser_params:N')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize predictions vs original\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "67e7f89d5252d36c0a7a22a0bddaf9ce6b4bb105a5aa258c373ad72ae6e9c8c8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('meta')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8002f67306fdf03846a85192394013d7a0803f94603193c08381e3348b7b52be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
